{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FwPAOtUAsb0"
      },
      "outputs": [],
      "source": [
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline('sentiment-analysis')"
      ],
      "metadata": {
        "id": "NhviULWuAvoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mail_sentiment():\n",
        "    # Get the input mail from the user\n",
        "    mail = input(\"Please enter your mail: \")\n",
        "\n",
        "    # Get the sentiment of the mail\n",
        "    sentiment_result = classifier(mail)\n",
        "\n",
        "    # Display the sentiment\n",
        "    print(\"\\nSentiment Analysis Result:\")\n",
        "    print(f\"Label: {sentiment_result[0]['label']}\")\n",
        "    print(f\"Confidence: {sentiment_result[0]['score']:.2f}\")\n",
        "\n",
        "# Test the function\n",
        "get_mail_sentiment()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUR5sIxHA0lo",
        "outputId": "c9b60171-6ddd-494d-ac48-168a4ebe667b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your mail: Subject: Kudos for Timely Medicine Delivery!  Dear [Recipient's Name/Pharmacy Team],  I hope this email finds you well. I wanted to take a moment to extend my sincere gratitude for the exceptional service I received from your team. In these challenging times, getting medicines on time is more crucial than ever, and your service surpassed my expectations.  The order was handled with utmost efficiency, and I was pleasantly surprised to receive my medicines right when I needed them. It's evident that your team prioritizes patient care, ensuring timely deliveries without compromising on the quality and safety of the medicines.  Your commitment to excellence sets you apart, and I am genuinely appreciative of the professionalism and care with which you handle each order. It's comforting to know that we can rely on [Pharmacy Name/Your team] for our medicinal needs.  Once again, thank you for your impeccable service. Please convey my appreciation to the entire team. I look forward to continuing to use your services in the future.\n",
            "\n",
            "Sentiment Analysis Result:\n",
            "Label: POSITIVE\n",
            "Confidence: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Hugging face"
      ],
      "metadata": {
        "id": "CmzkE0M5BZK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline('sentiment-analysis', model=\"nlptown/bert-base-multilingual-uncased-sentiment\")"
      ],
      "metadata": {
        "id": "nNHawsPNBdKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "RrwK9ed0BnH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "# This model only exists in PyTorch, so we use the `from_pt` flag to import that model in TensorFlow.\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, from_pt=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsUXvcaxCECN",
        "outputId": "87487f6f-4e09-493e-b643-0626612e8328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Setup the sentiment-analysis pipeline using the \"nlptown/bert-base-multilingual-uncased-sentiment\" model\n",
        "classifier_custom = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Test the function with the custom classifier\n",
        "print(\"\\nTesting with nlptown/bert-base-multilingual-uncased-sentiment model:\")\n",
        "get_mail_sentiment(classifier_custom)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T26NL6GBCKQY",
        "outputId": "e8a5a4d6-d50e-4efa-bb60-ef102f6a9cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing with nlptown/bert-base-multilingual-uncased-sentiment model:\n",
            "Please enter your mail: its a very bad product\n",
            "\n",
            "Sentiment Analysis Result:\n",
            "Label: 1 star\n",
            "Confidence: 0.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m56FOBK9DIbo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}